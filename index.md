
# Work Experience

## Genentech 
<center><img  src="images/Team1.png"/></center>

**Location:**  Oceanside, California
### Data Analyst & Strategy Deployment Intern

In my role, I worked closely with the Chief of Staff to drive strategic initiatives and optimize business processes. I identified use cases for RPA and supported resource management enhancements. This included creating interactive Tableau reports and assisting in the digitalization of huddle cascading and strategy deployment to enhance stakeholder connections.
  
**Key Accomplishments** 
1.  Enhanced Tableau dashboards for deviation management, resulting in a 73% reduction in machinery failures by assisting discrepancy owners in root cause analysis and corrective action planning.
    
2.  Utilized time series analysis to improve the efficiency of impacted processes by 47%, investigating breakdowns with trend analysis.
    
3.  Streamlined process orchestration and reduced manual data manipulation efforts by 25% through the development of ETL pipelines for the Intelligent Authoring tool.
    
4.  Led the digitalization of business processes and strategy deployment, resulting in a 65% increase in operational excellence and stakeholder satisfaction by fostering effective connections between various levels.
    
5.  Designed an NLP-based solution using BERTopic to analyze upticks in UPEs, identifying cluster trends, deviation types, and root causes to enhance RCA robustness.
    
6.  Spearheaded the automation of data extraction from Tableau dashboards into Trello boards, achieving dynamic updates and reducing manual data validation efforts by 90%.
    
7.  Initiated and conducted experiments to fine-tune the Langchain LLM model for Roche Internal use cases, improving its summarization capabilities and response refinement by 45%.

 
 

---

###  Identify cluster trends, deviation types, and possible root causes to increase RCA Robustness: BERTopic for Topic modeling 

  

[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1f32gj5IYIyFipoINiC8P3DvKat-WWLUK)

  

<div  style="text-align: justify"> Implemented an NLP solution using BERTopic to analyze and address an increase in Unplanned Events (UPEs) across various domains, including site operations, drug manufacturing, and biochemistry in upstream and downstream processes. The objective was to strengthen Root Cause Analysis (RCA) by identifying trends, deviation types, and root causes.

BERTopic allowed us to cluster UPE reports, revealing trends and highlighting clusters with frequent occurrences. We categorized different types of deviations within these clusters, gaining a deeper understanding of the issue's complexity.

Additionally, BERTopic helped us explore the root causes by examining keywords and contextual information within each cluster, aiding in RCA strategy development.

In summary, our NLP-based solution using BERTopic improved UPE analysis, enhancing RCA robustness and contributing to safer and more efficient operations in diverse domains</div>

  

<center><img  src="images/BERT-classification.png"/></center>

  

---

### Deviation Management: Tableau Dashboards

  

[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](projects/detect-food-trends-facebook.html)

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/chriskhanhtran/facebook-detect-food-trends)

  

<div  style="text-align: justify">First I build co-occurence matrices of ingredients from Facebook posts from 2011 to 2015. Then, to identify interesting and rare ingredient combinations that occur more than by chance, I calculate Lift and PPMI metrics. Lastly, I plot time-series data of identified trends to validate my findings. Interesting food trends have emerged from this analysis.</div>

<br>

<center><img  src="images/fb-food-trends.png"></center>

<br>

  

---

### Detect Spam Messages: TF-IDF and Naive Bayes Classifier

  

[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](projects/detect-spam-nlp.html)

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/chriskhanhtran/detect-spam-messages-nlp/blob/master/detect-spam-nlp.ipynb)

  

<div  style="text-align: justify">In order to predict whether a message is spam, first I vectorized text messages into a format that machine learning algorithms can understand using Bag-of-Word and TF-IDF. Then I trained a machine learning model to learn to discriminate between normal and spam messages. Finally, with the trained model, I classified unlabel messages into normal or spam.</div>

<br>

<center><img  src="images/detect-spam-nlp.png"/></center>

<br>

  

---

## Projects: Data Science & Business Analytics

  

### Credit Risk Prediction Web App

  

[![Open Web App](https://img.shields.io/badge/Heroku-Open_Web_App-blue?logo=Heroku)](http://credit-risk.herokuapp.com/)

[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](https://github.com/chriskhanhtran/credit-risk-prediction/blob/master/documents/Notebook.ipynb)

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/chriskhanhtran/credit-risk-prediction)

  

<div  style="text-align: justify">After my team preprocessed a dataset of 10K credit applications and built machine learning models to predict credit default risk, I built an interactive user interface with Streamlit and hosted the web app on Heroku server.</div>

<br>

<center><img  src="images/credit-risk-webapp.png"/></center>

<br>

  

---

### Kaggle Competition: Predict Ames House Price using Lasso, Ridge, XGBoost and LightGBM

  

[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](projects/ames-house-price.html)

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/chriskhanhtran/kaggle-house-price/blob/master/ames-house-price.ipynb)

  

<div  style="text-align: justify">I performed comprehensive EDA to understand important variables, handled missing values, outliers, performed feature engineering, and ensembled machine learning models to predict house prices. My best model had Mean Absolute Error (MAE) of 12293.919, ranking <b>95/15502</b>, approximately <b>top 0.6%</b> in the Kaggle leaderboard.</div>

<br>

<center><img  src="images/ames-house-price.jpg"/></center>

<br>

  

---

### Predict Breast Cancer with RF, PCA and SVM using Python

  

[![Open Notebook](https://img.shields.io/badge/Jupyter-Open_Notebook-blue?logo=Jupyter)](projects/breast-cancer.html)

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/chriskhanhtran/predict-breast-cancer-with-rf-pca-svm/blob/master/breast-cancer.ipynb)

  

<div  style="text-align: justify">In this project I am going to perform comprehensive EDA on the breast cancer dataset, then transform the data using Principal Components Analysis (PCA) and use Support Vector Machine (SVM) model to predict whether a patient has breast cancer.</div>

<br>

<center><img  src="images/breast-cancer.png"/></center>

<br>

  

---

### Business Analytics Conference 2018: How is NYC's Government Using Money?

  

[![Open Research Poster](https://img.shields.io/badge/PDF-Open_Research_Poster-blue?logo=adobe-acrobat-reader&logoColor=white)](pdf/bac2018.pdf)

  

<div  style="text-align: justify">In three-month research and a two-day hackathon, I led a team of four students to discover insights from 6 million records of NYC and Boston government spending data sets and won runner-up prize for the best research poster out of 18 participating colleges.</div>

<br>

<center><img  src="images/bac2018.JPG"/></center>

<br>

  

---

## Filmed by me

  

[![View My Films](https://img.shields.io/badge/YouTube-View_My_Films-grey?logo=youtube&labelColor=FF0000)](https://www.youtube.com/watch?v=vfZwdEWgUPE)

  

<div  style="text-align: justify">Besides Data Science, I also have a great passion for photography and videography. Below is a list of films I documented to retain beautiful memories of places I traveled to and amazing people I met on the way.</div>

<br>

 

---

<center>Â© 2020 Khanh Tran. Powered by Jekyll and the Minimal Theme.</center>